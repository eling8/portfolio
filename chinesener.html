<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Emily Ling - Portfolio</title>
        <link rel="icon" type="image/x-icon" href="assets/img/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v5.15.1/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Varela+Round" rel="stylesheet" />
        <link href="https://fonts.googleapis.com/css?family=Nunito:200,200i,300,300i,400,400i,600,600i,700,700i,800,800i,900,900i" rel="stylesheet" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css/styles.css" rel="stylesheet" />
    </head>
    <body id="page-top">
        <!-- Navigation-->
        <nav class="navbar navbar-expand-lg navbar-light fixed-top" id="mainNav">
            <div class="container">
                <a class="navbar-brand js-scroll-trigger" href="index.html">Emily Ling</a>
                <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarResponsive" aria-controls="navbarResponsive" aria-expanded="false" aria-label="Toggle navigation">
                    Menu
                    <i class="fas fa-bars"></i>
                </button>
                <div class="collapse navbar-collapse" id="navbarResponsive">
                    <ul class="navbar-nav ml-auto">
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="about.html">About</a></li>
                        <li class="nav-item"><a class="nav-link js-scroll-trigger" href="index.html#projects">Projects</a></li>
                    </ul>
                </div>
            </div>
        </nav>
        <!-- Masthead-->
        <section class="about-section text-center" id="about">
            <div class="container">
                <img class="img-project" src="assets/img/project-chinesener.png" alt="" />
                <div class="row">
                    <div class="col-lg-8 mx-auto">
                        </h4>
                        <h1 class="text-white mb-4">Named Entity Recognition and Compositional Morphology for Word Representations in Chinese</h1>
                        <p class="text-white-50">
                            Named entity recognition (NER) for Chinese, particularly using character and radical-level features.
                        </p>
                    </div>
                </div>
            </div>
        </section>
        <!-- Projects-->
        <section class="projects-section" id="projects">
            <div class="container">
                <div class="row justify-content-center no-gutters mb-5 mb-lg-0">
                    <div class="col-lg-2"></div>
                    <div class="col-lg-8">
                        <h4>Overview</h4>
                        <p>
                            As native Chinese speakers, we were interested in the task of named entity recognition (NER) on the Chinese written language.  We approached NER by representing each entity with a composition of its traits: the token, its characters, and its characters’ main radicals. We learn using neural networks with various combinations of the following traits: unidirectional or bidirectional; single or multi-layer; simple, gated recurrent unit (GRU), or long short term memory (LSTM) celled.
                        </p>

                        <h4>Details</h4>
                        <p>
                            The goal of NER is to take an input sentence and identify entities in the text which fall into categories such as PERSON, ORGANIZATION, and LOCATION. Because the Chinese and English languages have many key differences, we needed to adapt standard English NER approaches. These differences include:
                        </p> 
                        <ul>
                            <li>Chinese entities are composed of 50,000+ characters, whereas English entities which are composed of just 26 letters.</li>
                            <li>Each Chinese character holds intrinsic meaning, but also can take on a wide variety of meanings depending on which entity it is part of and its surrounding context.</li>
                            <li>Obvious English features used in NER such as word capitalization do not exist in Chinese.</li>
                            <li>The Chinese written language also does not contain spaces between entities, so word segmentation is an additional challenge.</li>
                        </ul>
                        <p>
                            In order to adapt to the uniqueness of the Chinese language, we used not only entity-level features but also character and radical-level features. In Chinese, each character has a main radical, which is a sub-part of a character. There are 214 radicals, and each radical conveys additional meaning behind each character. Take for example, the characters 食 (food), 餓 (hungry), 飯 (rice), and 餐 (meal). All of these characters have the main radical 食 and are related to food.
                        </p>
                        <p>
                            We experimented with 6 different combinations of input features, using token, character, and/or radical-level embeddings. These feature set types are shown below using the example token of 冰淇淋 (meaning ice cream):
                        </p>
                        <ul>
                            <li>token: the full token [冰淇淋]</li>
                            <li>char: each character is inputted and labeled independently [冰]</li>
                            <li>token-char: the token and first character of the token [冰淇淋 , 冰]</li>
                            <li>char-rad: each character and main radical of the character [冰 , 水]</li>
                            <li>token-char-char: the token and first and second characters of the token [冰淇淋 , 冰 , 淇]</li>
                            <li>token-char-rad: the token, first character of the token, and main radical of the first character [冰淇淋 , 冰 , 水]</li>
                        </ul>

                        <p>We also experimented with a number of different architectures for the recurrent neural network (RNN), including all permutations of the following:</p>
                        <ul>
                            <li>Simple, GRU (gated recurrent unit), or LSTM (long short-term memory) cells</li>
                            <li>Unidirectional or bidirectional RNN</li>
                            <li>Single or multi-layer RNN</li>
                            <li>Pretrained or randomly initialized embeddings. Pretrained word embeddings came from Facebook, and we trained character-level and radical-level embeddings ourselves using a skip-gram word2vec model.</li>
                        </ul>
                        <p>
                            Overall, we found that ”token-char-char” input features trained on the unidirectional RNN using pretrained Facebook word embeddings achieved the highest not-O F1 score of 76% and entity-level F1 score of 70%. 
                        </p>

                        <a class="btn btn-primary js-scroll-trigger" href="assets/files/chinesener-paper.pdf">Download the paper</a>
                    </div>

                    <div class="col-lg-2"></div>
                </div>

                <!-- Additional info -->
                <hr class="proj-divider mt-4" />
                <div class="row justify-content-center no-gutters mt-5">
                    <div class="col-lg-6">
                        <h2>Additional information</h2>
                    </div>
                    <div class="col-lg-6">
                        <p>
                            This was my final project for <i>Natural Language Processing with Deep Learning (CS224N/LINGUIST284)</i>, which I took during winter 2017 at Stanford University. The course focused on neural network models for NLP, including question answering and machine translation.
                        </p>
                        <p>
                            The project was done in partnership with two other students in the course. My primary contributions included: acquiring and cleaning data; implementing basic NER model as well as multilayer and bidirectional RNN; adding radical/token/character-level features; debugging model performance and tuning RNN hyperparameters.
                        </p>
                        <p><i>March 2017</i></p>
                    </div>
                </div>
            </div>
        </section>
        <!-- Contact-->
        <section class="contact-section bg-black">
            <div class="container">
                <div class="social d-flex justify-content-center">
                    <a class="mx-2" href="mailto:emilyx.ling@gmail.com"><i class="fas fa-envelope"></i></a>
                    <a class="mx-2" href="https://github.com/eling8"><i class="fab fa-github"></i></a>
                    <a class="mx-2" href="http://instagram.com/emling.photo"><i class="fab fa-instagram"></i></a>
                </div>
            </div>
        </section>
        <!-- Footer-->
        <footer class="footer bg-black small text-center text-white-50"><div class="container">Emily Ling, 2020</div></footer>
        <!-- Bootstrap core JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.5.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Third party plugin JS-->
        <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.4.1/jquery.easing.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
